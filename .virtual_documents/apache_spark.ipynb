!pip install pyspark



import pyspark


from pyspark.sql import SparkSession



import os

os.environ['SPARK_LOCAL_IP'] = '192.168.1.100'


spark=SparkSession.builder.appName('Practise').getOrCreate()


spark


df_spark = spark.read.csv("merc2.csv")


df_spark = spark.read.options(header="True", inferSchema=True).csv("merc2.csv")
# header="True" =>: This option specifies that the first row of the CSV file contains the column names.
# inferSchema=True =>  This option tells Spark to infer the data types of columns in the DataFrame based on the contents of the CSV file.


df_spark.show()


filtered_df_spark = df_spark.filter(df_spark.year>2004)


filtered_df_spark.show()


### Check the schema
df_spark.printSchema()


type(df_spark)


df_spark.head()


df_spark.head(3)


df_spark.select(["year", "price"]).show()


df_spark.dtypes



